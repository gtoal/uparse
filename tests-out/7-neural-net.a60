b̲e̲g̲i̲n̲
   c̲o̲m̲m̲e̲n̲t̲ Dieses neuronale Netzwerk hat einen Input-Layer mit zwei Eingangsknoten und eine Ausgabeschicht mit einem Ausgangsknoten. Es wird mit stochastischem Gradientenabstieg trainiert, um den Fehler zu minimieren und anschliessend auf Eingabewerte getestet;

   r̲e̲a̲l̲ a̲r̲r̲a̲y̲ input[1:2], weights[1:2];
   r̲e̲a̲l̲ bias, output, target;
   i̲n̲t̲e̲g̲e̲r̲ i, j, epochs;

   c̲o̲m̲m̲e̲n̲t̲ init and random bias;
   weights[1] := rand(0·0, 1·0);
   weights[2] := rand(0·0, 1·0);
   bias := rand(0·0, 1·0);

   target := 1·0;

   c̲o̲m̲m̲e̲n̲t̲ training / stochastic gradient descent;
   f̲o̲r̲ epochs := 1 s̲t̲e̲p̲ 1 u̲n̲t̲i̲l̲ 100 d̲o̲ b̲e̲g̲i̲n̲
         input[1] := rand(0·0, 1·0);
         input[2] := rand(0·0, 1·0);

         output := input[1] × weights[1] + input[2] × weights[2] + bias;

         c̲o̲m̲m̲e̲n̲t̲ compute error;
         error := target - output;

         c̲o̲m̲m̲e̲n̲t̲ update weights & bias w/ learning rate;
         weights[1] := weights[1] + error × input[1] × 0·1;
         weights[2] := weights[2] + error × input[2] × 0·1;
         bias := bias + error × 0·1;
      e̲n̲d̲;

   c̲o̲m̲m̲e̲n̲t̲ test;
   input[1] := 0·5;
   input[2] := 0·7;

   c̲o̲m̲m̲e̲n̲t̲ compute;
   output := input[1] × weights[1] + input[2] × weights[2] + bias;

   print(output);
e̲n̲d̲;
